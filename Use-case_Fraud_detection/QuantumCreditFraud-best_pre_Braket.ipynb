{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d91699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/Braket/lib/python3.7/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /home/ec2-user/anaconda3/envs/Braket/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK2at10TensorBase21__dispatch_contiguousEN3c1012MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# Imported Libraries\n",
    "import pennylane as qml\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "from pennylane import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from graphs import plot_correlation_matrix\n",
    "import random\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05159f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path\n",
    "sys.path.append \n",
    "\n",
    "from qencode.initialize import setAB_amplitude, setAux, setEnt\n",
    "from qencode.encoders import e2_classic\n",
    "from qencode.training_circuits import swap_t\n",
    "from qencode.qubits_arrangement import QubitsArrangement\n",
    "\n",
    "from qencode.utils.mnist import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f846af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.3-cp37-cp37m-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.2 MB 18.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/Braket/lib/python3.7/site-packages (from torchvision) (1.19.2)\n",
      "Collecting pillow!=8.3.0,>=5.3.0\n",
      "  Downloading Pillow-9.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 74.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.10.2\n",
      "  Downloading torch-1.10.2-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[K     |██████████████████████████████▋ | 844.9 MB 88.7 MB/s eta 0:00:01    |█                               | 24.5 MB 61.7 MB/s eta 0:00:14█▊                          | 159.2 MB 81.0 MB/s eta 0:00:09     |██████▍                         | 176.5 MB 81.0 MB/s eta 0:00:09:00:04     |██████████████████████▏         | 610.4 MB 89.5 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 881.9 MB 1.0 kB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/Braket/lib/python3.7/site-packages (from torch==1.10.2->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torch, pillow, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.1\n",
      "    Uninstalling torch-1.9.1:\n",
      "      Successfully uninstalled torch-1.9.1\n",
      "Successfully installed pillow-9.0.1 torch-1.10.2 torchvision-0.11.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3db81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "#import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "#https://www.kaggle.com/mlg-ulb/creditcardfraud/download\n",
    "#downloading datasets for COVID-19 data\n",
    "#api.dataset_download_files('imdevskp/corona-virus-report')\n",
    "api.dataset_download_files('mlg-ulb/creditcardfraud')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd7752",
   "metadata": {},
   "source": [
    "# Credit Card Fraud - A Growing Issue\n",
    "\n",
    "Credit card fraud is a growing issue with \\\\$28.5 billion lost globally due to credit card fraud in 2020 and is expected to exceed \\\\$49 billion by 2030 [1]). In 2020, around 1 out of 4 digital interactions were credit card fraud attempts (Cite Arkose Labs). Since there are so many non fraudulent transactions, it is challenging to detect the fraudulent transactions. In this notebook, we will be using a quantum auto-encoder to perform anomaly detection. \n",
    "\n",
    "We can use the quantum auto encoder to encode the 4 qubit state into a 3 qubit state and then use a decoder to decode the 3 qubit state back into 4 qubit state. The quantum auto encoder is trained on the normal dataset (or in this case the non fraudulent transactions) which means the quantum auto \n",
    "To tell if a datapoint is an anomaly, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03120a4",
   "metadata": {},
   "source": [
    "Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3846e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ad462",
   "metadata": {},
   "source": [
    "We are only going to print the first 5 rows because the dataset contains over 280,000 rows. Each row represents a transaction. Time shows the time passed between the current and first transactions and amount shows the dollar amount spent on the transaction. There are also 28 more features represented by V1, V2, ... , V28 which come from principal component analysis. Finally, there is the class, where a '0' represents no fraud committed and a '1' represents a fraudulent transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54abc9",
   "metadata": {},
   "source": [
    "Let's now check the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162a2de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds:  284315\n",
      "Frauds:  492\n"
     ]
    }
   ],
   "source": [
    "print('No Frauds: ', df['Class'].value_counts()[0])\n",
    "print('Frauds: ', df['Class'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64dbf3",
   "metadata": {},
   "source": [
    "Credit card fraud is relatively rare, this creates a very imbalanced distribution. A very imbalanced distribution is not ideal as this can lead to overfitting and our model assuming no fraud most of the time. It is also challenging to find the true correlations between the features and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1b6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(df, \"Original Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07de964",
   "metadata": {},
   "source": [
    "As you can see, nothing can really be inferred from this correlation matrix since the data is so imbalanced. We are going to create a sub sample dataset with equal amounts of non fraudulent data and fraudulent data. We are also going to scale the 'Time' and 'Amount' values for better processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c077e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87972</th>\n",
       "      <td>0.020960</td>\n",
       "      <td>-0.267461</td>\n",
       "      <td>1.281877</td>\n",
       "      <td>0.254411</td>\n",
       "      <td>-0.145903</td>\n",
       "      <td>0.535227</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>-0.879058</td>\n",
       "      <td>0.362845</td>\n",
       "      <td>-0.304855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031597</td>\n",
       "      <td>-0.074526</td>\n",
       "      <td>-0.202006</td>\n",
       "      <td>-0.142884</td>\n",
       "      <td>-0.067349</td>\n",
       "      <td>0.641961</td>\n",
       "      <td>0.395226</td>\n",
       "      <td>-0.053546</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218442</th>\n",
       "      <td>2.426605</td>\n",
       "      <td>0.665280</td>\n",
       "      <td>-6.352337</td>\n",
       "      <td>-2.370335</td>\n",
       "      <td>-4.875397</td>\n",
       "      <td>2.335045</td>\n",
       "      <td>-0.809555</td>\n",
       "      <td>-0.413647</td>\n",
       "      <td>-4.082308</td>\n",
       "      <td>2.239089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186898</td>\n",
       "      <td>1.325218</td>\n",
       "      <td>1.226745</td>\n",
       "      <td>-1.485217</td>\n",
       "      <td>-1.470732</td>\n",
       "      <td>-0.240053</td>\n",
       "      <td>0.112972</td>\n",
       "      <td>0.910591</td>\n",
       "      <td>-0.650944</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227450</th>\n",
       "      <td>-0.293440</td>\n",
       "      <td>0.709466</td>\n",
       "      <td>-0.378099</td>\n",
       "      <td>0.313166</td>\n",
       "      <td>0.889931</td>\n",
       "      <td>-0.799382</td>\n",
       "      <td>0.890967</td>\n",
       "      <td>-0.961934</td>\n",
       "      <td>0.972766</td>\n",
       "      <td>-0.383644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023204</td>\n",
       "      <td>0.123826</td>\n",
       "      <td>0.693484</td>\n",
       "      <td>-0.376556</td>\n",
       "      <td>-0.048078</td>\n",
       "      <td>0.096518</td>\n",
       "      <td>0.130284</td>\n",
       "      <td>-0.054488</td>\n",
       "      <td>-0.076143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128479</th>\n",
       "      <td>0.530986</td>\n",
       "      <td>-0.070102</td>\n",
       "      <td>-4.312479</td>\n",
       "      <td>1.886476</td>\n",
       "      <td>-2.338634</td>\n",
       "      <td>-0.475243</td>\n",
       "      <td>-1.185444</td>\n",
       "      <td>-2.112079</td>\n",
       "      <td>-2.122793</td>\n",
       "      <td>0.272565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.718706</td>\n",
       "      <td>0.550541</td>\n",
       "      <td>-0.067870</td>\n",
       "      <td>-1.114692</td>\n",
       "      <td>0.269069</td>\n",
       "      <td>-0.020572</td>\n",
       "      <td>-0.963489</td>\n",
       "      <td>-0.918888</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157868</th>\n",
       "      <td>-0.296793</td>\n",
       "      <td>0.303751</td>\n",
       "      <td>-1.532810</td>\n",
       "      <td>2.232752</td>\n",
       "      <td>-5.923100</td>\n",
       "      <td>3.386708</td>\n",
       "      <td>-0.153443</td>\n",
       "      <td>-1.419748</td>\n",
       "      <td>-3.878576</td>\n",
       "      <td>1.444656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520840</td>\n",
       "      <td>0.632505</td>\n",
       "      <td>-0.070838</td>\n",
       "      <td>-0.490291</td>\n",
       "      <td>-0.359983</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>1.095671</td>\n",
       "      <td>0.471741</td>\n",
       "      <td>-0.106667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "87972        0.020960    -0.267461  1.281877  0.254411 -0.145903  0.535227   \n",
       "218442       2.426605     0.665280 -6.352337 -2.370335 -4.875397  2.335045   \n",
       "227450      -0.293440     0.709466 -0.378099  0.313166  0.889931 -0.799382   \n",
       "128479       0.530986    -0.070102 -4.312479  1.886476 -2.338634 -0.475243   \n",
       "157868      -0.296793     0.303751 -1.532810  2.232752 -5.923100  3.386708   \n",
       "\n",
       "              V5        V6        V7        V8  ...       V20       V21  \\\n",
       "87972   0.019784 -0.879058  0.362845 -0.304855  ... -0.031597 -0.074526   \n",
       "218442 -0.809555 -0.413647 -4.082308  2.239089  ...  0.186898  1.325218   \n",
       "227450  0.890967 -0.961934  0.972766 -0.383644  ... -0.023204  0.123826   \n",
       "128479 -1.185444 -2.112079 -2.122793  0.272565  ... -0.718706  0.550541   \n",
       "157868 -0.153443 -1.419748 -3.878576  1.444656  ...  0.520840  0.632505   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "87972  -0.202006 -0.142884 -0.067349  0.641961  0.395226 -0.053546  0.005030   \n",
       "218442  1.226745 -1.485217 -1.470732 -0.240053  0.112972  0.910591 -0.650944   \n",
       "227450  0.693484 -0.376556 -0.048078  0.096518  0.130284 -0.054488 -0.076143   \n",
       "128479 -0.067870 -1.114692  0.269069 -0.020572 -0.963489 -0.918888  0.001454   \n",
       "157868 -0.070838 -0.490291 -0.359983  0.050678  1.095671  0.471741 -0.106667   \n",
       "\n",
       "        Class  \n",
       "87972       0  \n",
       "218442      1  \n",
       "227450      0  \n",
       "128479      1  \n",
       "157868      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Scaling amount and time for the subsample\n",
    "df['scaled_amount'] = RobustScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = RobustScaler().fit_transform(df['Time'].values.reshape(-1,1))\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True) # Drop the original time and amount values\n",
    "\n",
    "# Add scaled amount and times to the data frame\n",
    "scaled_amount = df['scaled_amount'] \n",
    "scaled_time = df['scaled_time']\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "# Create the balanced subsample of 49\n",
    "df = df.sample(frac=1)\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "sub_sample_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Display the first 5 rows t ose\n",
    "sub_sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19080690",
   "metadata": {},
   "source": [
    "We can now plot the correlation matrix of our new sub sample to get a better idea of the true correlations between features and 'Class' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99e158d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sample_corr = sub_sample_df.corr()\n",
    "plot_correlation_matrix(sub_sample_corr, \"Sub Sample Correlation Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2ef55",
   "metadata": {},
   "source": [
    "The correlations are now much more noticeable. Now, we can find the features with the strongest correlation to class. Half are the strongest positive correlations, half are the strongest negative correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88040b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['V4', 'V14', 'V11', 'V12', 'V2', 'V10', 'V19', 'V16', 'V20', 'V9', 'V21', 'V3', 'V28', 'V17', 'V27', 'V7'], [0.7211980893293823, -0.7517209646906146, 0.6934701844282471, -0.6848674234383837, 0.492405053522152, -0.6192313003963814, 0.278836598111022, -0.5913009967861621, 0.18495339501702748, -0.5831508529466832, 0.12784531878929187, -0.5674471056206869, 0.08757252744115403, -0.5581046843201575, 0.0713419111838715, -0.4801694818094904])\n"
     ]
    }
   ],
   "source": [
    "def find_strongest_correlations(dataframe, latent_qubits):\n",
    "    \n",
    "    num_features = latent_qubits**2\n",
    "    \n",
    "    class_correlations = dataframe.loc['Class', :]\n",
    "    class_correlations = class_correlations.drop(index = 'Class')\n",
    "    \n",
    "    feature_list = list(class_correlations.index)\n",
    "    correlation_list = [class_correlations[x] for x in feature_list]\n",
    "    \n",
    "    features = []\n",
    "    correlations = []\n",
    "    \n",
    "    for i in range(int(num_features/2)):\n",
    "        \n",
    "        \n",
    "        correlations.append(max(correlation_list))\n",
    "        features.append(feature_list[correlation_list.index(max(correlation_list))])\n",
    "        \n",
    "        del feature_list[correlation_list.index(max(correlation_list))]\n",
    "        del correlation_list[correlation_list.index(max(correlation_list))]                        \n",
    "                                      \n",
    "        correlations.append(min(correlation_list))\n",
    "        features.append(feature_list[correlation_list.index(min(correlation_list))])\n",
    "        \n",
    "        del feature_list[correlation_list.index(min(correlation_list))]\n",
    "        del correlation_list[correlation_list.index(min(correlation_list))] \n",
    "    \n",
    "    return features, correlations\n",
    "\n",
    "feature_list, correlations = find_strongest_correlations(sub_sample_corr, 4)\n",
    "\n",
    "print(find_strongest_correlations(sub_sample_corr, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b9c62",
   "metadata": {},
   "source": [
    "We now have 16 features that are the most correlated with 'Class'. In this use case, we will be using 4 qubits to represent the data which means we will need 2$^{4}$ = 16 features to encode into the 4 qubits though amplitude encoding. Later, we will use the quantum autoencoder to encode the 4 qubits into 3 qubits and then use a decoder to decode those 3 qubits back to 4 qubits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "193fe113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe of all non fraudulent transactions\n",
    "branch = df\n",
    "non_fraud = branch[branch[\"Class\"]!=\"1\"][:200]\n",
    "\n",
    "# All examples of non fraudulent data with 16 features\n",
    "non_fraud = non_fraud[feature_list][:200]\n",
    "non_fraud.head()\n",
    "\n",
    "input_data = non_fraud.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f33cad",
   "metadata": {},
   "source": [
    "# Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ee0ea5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qubits: [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "shots = 2500 #The amount of shots used for each epoch of training\n",
    "nr_trash= 1   # Number of qubits 'thrown away'\n",
    "nr_latent= 3  # Number of qubits left after the encoder is used\n",
    "nr_ent = 0\n",
    "\n",
    "epochs = 500   # Number of iterations of training to perform to find the final encoder parameters\n",
    "learning_rate = .005 # Learning rate for the optimizer, dictates how fast the optimizer trains\n",
    "batch_size = 2\n",
    "num_samples = 50  # Number of training samples used for each epoch\n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "opt = AdamOptimizer(learning_rate, beta1=beta1, beta2=beta2)\n",
    "\n",
    "# Organizes and specifies our qubits for the device\n",
    "spec = QubitsArrangement(nr_trash, nr_latent, nr_swap=1, nr_ent=nr_ent)\n",
    "\n",
    "\n",
    "#set up the device \n",
    "\n",
    "#dev = qml.device(\"default.qubit\", wires=spec.num_qubits)\n",
    "dev = qml.device(\"braket.local.qubit\", wires=spec.num_qubits, shots = 2500)\n",
    "\n",
    "print(\"Qubits:\", spec.qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85c89846",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface = \"autograd\")\n",
    "def training_circuit_example(init_params, encoder_params, reinit_state):\n",
    "    #initilaization\n",
    "    setAB_amplitude(spec, init_params)\n",
    "\n",
    "    setAux(spec, reinit_state)\n",
    "\n",
    "    setEnt(spec, inputs=[1 / np.sqrt(2), 0, 0, 1 / np.sqrt(2)])\n",
    "\n",
    "    #encoder \n",
    "\n",
    "    for params in encoder_params:\n",
    "        e2_classic(params, [*spec.latent_qubits, *spec.trash_qubits])\n",
    "\n",
    "    #swap test \n",
    "    swap_t(spec)\n",
    "\n",
    "    return [qml.probs(i) for i in spec.swap_qubits]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3277892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_func(output):\n",
    "    # Implemented as the Fidelity Loss\n",
    "    # output[0] because we take the probability that the state after the \n",
    "    # SWAP test is ket(0), like the reference state\n",
    "    fidelity_loss = 1 / output[0]\n",
    "    return fidelity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2c4b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cost function\n",
    "def cost(encoder_params, X):\n",
    "    reinit_state = [0 for i in range(2 ** len(spec.aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output = training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state)[0]\n",
    "        f = fid_func(output)\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a80ca440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fidelity function\n",
    "def fidelity(encoder_params, X):\n",
    "    reinit_state = [0 for i in range(2 ** len(spec.aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output = training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state)[0]\n",
    "        f = output[0]\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(X, batch_size):\n",
    "    \n",
    "    random.shuffle(X)\n",
    "\n",
    "    batch_list = []\n",
    "    batch = []\n",
    "    for x in X:\n",
    "        if len(batch) < batch_size:\n",
    "            batch.append(x)\n",
    "\n",
    "        else:\n",
    "            batch_list.append(batch)\n",
    "            batch = []\n",
    "    if len(batch) != 0:\n",
    "        batch_list.append(batch)\n",
    "    return batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data = [ torch.tensor([input_data[i]]) for i in range(num_samples)]\n",
    "test_data = [ torch.tensor([input_data[i]]) for i in range(num_samples,num_samples+num_samples)]\n",
    "\n",
    "X_training = training_data\n",
    "X_tes = test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8725d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d31955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6ad9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11525974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random encoder parameters\n",
    "nr_encod_qubits = len(spec.trash_qubits) + len(spec.latent_qubits)\n",
    "nr_par_encoder =  15 * int(nr_encod_qubits*(nr_encod_qubits-1)/2)\n",
    "encoder_params = np.random.uniform(size=(1, nr_par_encoder), requires_grad=True)\n",
    "print(encoder_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c97148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbf0aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params=[[-0.45793534, -0.60180382,  1.36706854, -0.39273726,  0.78967496,\n",
    "         -0.11834691,  1.21601293,  0.7257659 ,  0.16775198,  0.87110514,\n",
    "          0.5825973 ,  1.35786832,  1.6198694 , -0.21858262,  1.41542989,\n",
    "          1.2968311 ,  1.8630585 ,  0.50511886,  0.75524677,  0.82482716,\n",
    "          1.02949018, -0.023521  ,  0.55110408,  0.15877528,  0.62316124,\n",
    "          0.37113699,  0.4557925 ,  0.62940097,  0.61549768,  0.95122916,\n",
    "          0.22349399,  0.86457997,  0.81546047,  1.47984623,  1.72818011,\n",
    "         -0.30175269,  0.67999145, -0.22226086,  0.94370564,  1.48028116,\n",
    "          0.72720142,  0.20210445,  0.14995309,  0.19133051, -0.35101019,\n",
    "          0.40932117, -0.09846242,  0.65960454,  0.78151562,  1.17058629,\n",
    "          0.23858532,  0.71485483,  0.31327769,  1.63693523,  0.95525645,\n",
    "          0.58935465,  0.76165831,  0.62729872,  0.55561916,  0.19378356,\n",
    "          0.41408805,  1.01374824,  0.37282255, -0.06769513,  0.45583351,\n",
    "         -0.05101048,  0.83344398,  1.58156091,  1.46059524,  0.9371276 ,\n",
    "          0.96522386,  0.27626285,  0.19818911,  0.11227637,  0.38220371,\n",
    "          0.64166103,  0.92703234,  0.3736458 ,  0.21161801,  0.62412085,\n",
    "          0.3278856 , -0.18893975,  0.86769553,  0.78573112,  0.50142613,\n",
    "          0.96622037,  0.40300401,  0.55802604,  0.12912973,  0.14822851]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(encoder_params)\n",
    "\n",
    "#reinit_state = [0 for i in range(2 ** 4)]\n",
    "#reinit_state[0] = 1.0\n",
    "print(reinit_state)\n",
    "print(len(spec.aux_qubits))\n",
    "#print(training_circuit_example(encoder_params, encoder_params, reinit_state = reinit_state))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3364179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor dataset with only fraud data and most correlated features \n",
    "# for finding the fidelity of the quantum autoencoder on fraud transactions\n",
    "\n",
    "fraud = fraud_df[feature_list]\n",
    "np_fraud = fraud.to_numpy()\n",
    "fraud_data = [ torch.tensor([np_fraud[i]]) for i in range(len(fraud.to_numpy()))] \n",
    "\n",
    "fraud.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist=[]\n",
    "fid_hist=[]\n",
    "\n",
    "loss_hist_test=[]\n",
    "fid_hist_test=[]\n",
    "\n",
    "fraud_fid=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batches = iterate_batches(X=training_data, batch_size=batch_size)\n",
    "    for xbatch in batches:\n",
    "        encoder_params = opt.step(cost, encoder_params, X=xbatch)\n",
    "\n",
    "        \n",
    "    if epoch%5 == 0:\n",
    "        \n",
    "        loss_training = cost(encoder_params, X_training )\n",
    "        fidel = fidelity(encoder_params, X_training )\n",
    "        \n",
    "        loss_hist.append(loss_training)\n",
    "        fid_hist.append(fidel)\n",
    "        print(\"Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_training, fidel))\n",
    "\n",
    "        loss_test = cost(encoder_params, X_tes )\n",
    "        fidel = fidelity(encoder_params, X_tes )\n",
    "        loss_hist_test.append(loss_test)\n",
    "        fid_hist_test.append(fidel)\n",
    "        print(\"Test-Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_test, fidel))\n",
    "        \n",
    "        f_fidel = fidelity(encoder_params, fraud_data )\n",
    "        fraud_fid.append(f_fidel)\n",
    "        print(\"Fraud Fidelity:{}\".format(f_fidel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a6b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist),label=\"train fidelity\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist_test),label=\"test fidelity\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fraud_fid),label=\"fraud fidelity\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Fraud 4-3-4 Compression Fidelity e2 Braket\",)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Fidelity\")\n",
    "plt.savefig(\"Fraud 4-3-4 Compression Fidelity e2 Braket\")\n",
    "\n",
    "print(\"fidelity:\",fid_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist),label=\"train loss\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist_test),label=\"test loss\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Fraud 4-3-4 Compression Loss e2\",)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(\"Fraud 4-3-4 Compression Loss e2\")\n",
    "\n",
    "print(\"loss:\",loss_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"fraud_434_training_e2\"\n",
    "\n",
    "Circuit_prop={   \"shots\":shots, \"nr_trash\":nr_trash, \"nr_latent\":nr_latent, \"nr_ent\":nr_ent  }\n",
    "Training_param = { \"num_samples\" == num_samples,\n",
    "                    \"batch_size\" == batch_size,\n",
    "                    #\"nr_layers\"== nr_layers,\n",
    "                    \"epochs\" == epochs,\n",
    "                    \"learning_rate\" == learning_rate, \n",
    "                    \"beta1\" == beta1,\n",
    "                    \"beta2 \"== beta2,\n",
    "                     \"optimizer\"==\"Adam\"}\n",
    "\n",
    "performance={\"loss_hist\":loss_hist, \"fid_hist\":fid_hist,\n",
    "             \"loss_hist_test\":loss_hist_test, \"fid_hist_test\":fid_hist_test,\n",
    "             \"encoder_params\":encoder_params}\n",
    "\n",
    "experiment_data={\"Circuit_prop\":Circuit_prop,\n",
    "                \"Training_param\":Training_param,\n",
    "                \"performance:\":performance,\n",
    "                \"Name\":name}\n",
    "\n",
    "# open file for writing\n",
    "f = open(name+\".txt\",\"w\")\n",
    "f.write( str(experiment_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_parameters={\"autoencoder\":\"e2\",\"params\":encoder_params}\n",
    "f=open(\"Params_Fraud_encoder_e2-CorrelatedFeautures.txt\",\"w\")\n",
    "f.write(str(experiment_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df7aec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6052\n",
      "0.982\n"
     ]
    }
   ],
   "source": [
    "branch = df \n",
    "non_fraud_df = branch.loc[branch[\"Class\"]!=1][:200]\n",
    "\n",
    "\n",
    "non_fraud = non_fraud_df[feature_list]\n",
    "np_non_fraud = non_fraud.to_numpy()\n",
    "non_fraud_data = [ torch.tensor([np_non_fraud[i]]) for i in range(len(non_fraud.to_numpy()))]\n",
    "\n",
    "non_fraud_flist=[]\n",
    "for b in non_fraud_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    non_fraud_flist.append(f.item())\n",
    "    \n",
    "print(min(non_fraud_flist))\n",
    "print(max(non_fraud_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "081c277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5404\n",
      "0.94\n"
     ]
    }
   ],
   "source": [
    "#np_ilegal= ilegal.to_numpy()\n",
    "#ilegal_data = [ torch.tensor([np_ilegal[i]]) for i in range(len(ilegal.to_numpy()))]\n",
    "fraud_df = branch.loc[branch[\"Class\"]==1][:200]\n",
    "non_fraud = fraud_df[feature_list]\n",
    "np_non_fraud = non_fraud.to_numpy()\n",
    "fraud_data = [ torch.tensor([np_non_fraud[i]]) for i in range(len(non_fraud.to_numpy()))]\n",
    "\n",
    "\n",
    "\n",
    "fraud_flist=[]\n",
    "for b in fraud_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    fraud_flist.append(f.item())\n",
    "    \n",
    "print(min(fraud_flist))\n",
    "print(max(fraud_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "317b50bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(non_fraud_flist, bins =100 ,label=\"non_fraud\",color = \"red\",alpha=0.4)\n",
    "plt.hist(fraud_flist, bins = 100 ,label=\"fraud\", color = \"skyblue\",alpha=0.4)\n",
    "plt.title(\"Compression fidelity\",)\n",
    "plt.legend()\n",
    "plt.savefig(\"Compression_fidelity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8559582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: 0.75\n",
      "benign classification accuracy: 0.83\n",
      "malignification accuracy: 0.93\n",
      "total accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "split=0.75\n",
    "\n",
    "\n",
    "print(\"split:\",split)\n",
    "b_e=[]\n",
    "for i in fraud_flist:\n",
    "    if i<split:\n",
    "        b_e.append(1)\n",
    "    else:\n",
    "        b_e.append(0)\n",
    "ab_ac=sum(b_e)/len(b_e)\n",
    "print(\"benign classification accuracy:\",ab_ac)\n",
    "m_e=[]\n",
    "for i in non_fraud_flist:\n",
    "    if i>split:\n",
    "        m_e.append(1)\n",
    "    else:\n",
    "        m_e.append(0)\n",
    "am_ac=sum(m_e)/len(m_e)\n",
    "print(\"malignification accuracy:\",am_ac)\n",
    "t_ac=(sum(b_e)+sum(m_e))/(len(b_e)+len(m_e))\n",
    "print(\"total accuracy:\",t_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39420a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcce47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9cdbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
