{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\tomut\\anaconda3\\envs\\qhack2022\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from graphs import plot_correlation_matrix\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#quanutm lib\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path\n",
    "\n",
    "from qencode.initialize import setAB_amplitude, setAux, setEnt\n",
    "from qencode.encoders import e5_patch\n",
    "from qencode.training_circuits import swap_t\n",
    "from qencode.qubits_arrangement import QubitsArrangement\n",
    "\n",
    "from qencode.utils.mnist import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"cancer.csv\", nrows=500)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## malign and benign aee reverted !!!!!!!!!!!!!\n",
    "\n",
    "diagnosis=[]\n",
    "for d in df.diagnosis:\n",
    "    if d==\"M\":\n",
    "        diagnosis.append(1.0)\n",
    "    else:\n",
    "        diagnosis.append(0.0)\n",
    "df[\"diagnosis\"]=diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malign:  305\n",
      "Benign:  195\n"
     ]
    }
   ],
   "source": [
    "print('Malign: ', df['diagnosis'].value_counts()[0])\n",
    "print('Benign: ', df['diagnosis'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       500 non-null    int64  \n",
      " 1   diagnosis                500 non-null    float64\n",
      " 2   radius_mean              500 non-null    float64\n",
      " 3   texture_mean             500 non-null    float64\n",
      " 4   perimeter_mean           500 non-null    float64\n",
      " 5   area_mean                500 non-null    float64\n",
      " 6   smoothness_mean          500 non-null    float64\n",
      " 7   compactness_mean         500 non-null    float64\n",
      " 8   concavity_mean           500 non-null    float64\n",
      " 9   concave points_mean      500 non-null    float64\n",
      " 10  symmetry_mean            500 non-null    float64\n",
      " 11  fractal_dimension_mean   500 non-null    float64\n",
      " 12  radius_se                500 non-null    float64\n",
      " 13  texture_se               500 non-null    float64\n",
      " 14  perimeter_se             500 non-null    float64\n",
      " 15  area_se                  500 non-null    float64\n",
      " 16  smoothness_se            500 non-null    float64\n",
      " 17  compactness_se           500 non-null    float64\n",
      " 18  concavity_se             500 non-null    float64\n",
      " 19  concave points_se        500 non-null    float64\n",
      " 20  symmetry_se              500 non-null    float64\n",
      " 21  fractal_dimension_se     500 non-null    float64\n",
      " 22  radius_worst             500 non-null    float64\n",
      " 23  texture_worst            500 non-null    float64\n",
      " 24  perimeter_worst          500 non-null    float64\n",
      " 25  area_worst               500 non-null    float64\n",
      " 26  smoothness_worst         500 non-null    float64\n",
      " 27  compactness_worst        500 non-null    float64\n",
      " 28  concavity_worst          500 non-null    float64\n",
      " 29  concave points_worst     500 non-null    float64\n",
      " 30  symmetry_worst           500 non-null    float64\n",
      " 31  fractal_dimension_worst  500 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(32), int64(1)\n",
      "memory usage: 129.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.263049e+07</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>14.224206</td>\n",
       "      <td>19.086320</td>\n",
       "      <td>92.606620</td>\n",
       "      <td>662.844800</td>\n",
       "      <td>0.095978</td>\n",
       "      <td>0.103948</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.049446</td>\n",
       "      <td>...</td>\n",
       "      <td>25.508500</td>\n",
       "      <td>108.258320</td>\n",
       "      <td>896.003200</td>\n",
       "      <td>0.131972</td>\n",
       "      <td>0.256324</td>\n",
       "      <td>0.276420</td>\n",
       "      <td>0.115980</td>\n",
       "      <td>0.292212</td>\n",
       "      <td>0.083778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.326933e+08</td>\n",
       "      <td>0.488238</td>\n",
       "      <td>3.476809</td>\n",
       "      <td>4.164842</td>\n",
       "      <td>23.983476</td>\n",
       "      <td>349.357241</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>0.053096</td>\n",
       "      <td>0.080259</td>\n",
       "      <td>0.038875</td>\n",
       "      <td>...</td>\n",
       "      <td>6.063133</td>\n",
       "      <td>33.312706</td>\n",
       "      <td>571.074422</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.159147</td>\n",
       "      <td>0.209012</td>\n",
       "      <td>0.065896</td>\n",
       "      <td>0.063366</td>\n",
       "      <td>0.018108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.667040e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.807500</td>\n",
       "      <td>16.070000</td>\n",
       "      <td>75.995000</td>\n",
       "      <td>430.550000</td>\n",
       "      <td>0.085992</td>\n",
       "      <td>0.063622</td>\n",
       "      <td>0.028885</td>\n",
       "      <td>0.020245</td>\n",
       "      <td>...</td>\n",
       "      <td>21.017500</td>\n",
       "      <td>84.567500</td>\n",
       "      <td>522.600000</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.145925</td>\n",
       "      <td>0.114475</td>\n",
       "      <td>0.063302</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.071270</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.014320e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.435000</td>\n",
       "      <td>18.680000</td>\n",
       "      <td>86.735000</td>\n",
       "      <td>556.150000</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>0.091280</td>\n",
       "      <td>0.064315</td>\n",
       "      <td>0.033870</td>\n",
       "      <td>...</td>\n",
       "      <td>25.240000</td>\n",
       "      <td>97.980000</td>\n",
       "      <td>691.750000</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.214850</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.100650</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.910808e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.115000</td>\n",
       "      <td>21.562500</td>\n",
       "      <td>106.225000</td>\n",
       "      <td>800.775000</td>\n",
       "      <td>0.105100</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>0.132150</td>\n",
       "      <td>0.074928</td>\n",
       "      <td>...</td>\n",
       "      <td>29.350000</td>\n",
       "      <td>127.150000</td>\n",
       "      <td>1150.750000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.343525</td>\n",
       "      <td>0.389450</td>\n",
       "      <td>0.166850</td>\n",
       "      <td>0.320050</td>\n",
       "      <td>0.092065</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "count  5.000000e+02  500.000000   500.000000    500.000000      500.000000   \n",
       "mean   3.263049e+07    0.390000    14.224206     19.086320       92.606620   \n",
       "std    1.326933e+08    0.488238     3.476809      4.164842       23.983476   \n",
       "min    8.670000e+03    0.000000     6.981000      9.710000       43.790000   \n",
       "25%    8.667040e+05    0.000000    11.807500     16.070000       75.995000   \n",
       "50%    9.014320e+05    0.000000    13.435000     18.680000       86.735000   \n",
       "75%    8.910808e+06    1.000000    16.115000     21.562500      106.225000   \n",
       "max    9.113205e+08    1.000000    28.110000     39.280000      188.500000   \n",
       "\n",
       "         area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "count   500.000000       500.000000        500.000000      500.000000   \n",
       "mean    662.844800         0.095978          0.103948        0.089941   \n",
       "std     349.357241         0.013666          0.053096        0.080259   \n",
       "min     143.500000         0.062510          0.019380        0.000000   \n",
       "25%     430.550000         0.085992          0.063622        0.028885   \n",
       "50%     556.150000         0.095825          0.091280        0.064315   \n",
       "75%     800.775000         0.105100          0.130500        0.132150   \n",
       "max    2501.000000         0.144700          0.345400        0.426800   \n",
       "\n",
       "       concave points_mean  ...  texture_worst  perimeter_worst   area_worst  \\\n",
       "count           500.000000  ...     500.000000       500.000000   500.000000   \n",
       "mean              0.049446  ...      25.508500       108.258320   896.003200   \n",
       "std               0.038875  ...       6.063133        33.312706   571.074422   \n",
       "min               0.000000  ...      12.020000        50.410000   185.200000   \n",
       "25%               0.020245  ...      21.017500        84.567500   522.600000   \n",
       "50%               0.033870  ...      25.240000        97.980000   691.750000   \n",
       "75%               0.074928  ...      29.350000       127.150000  1150.750000   \n",
       "max               0.201200  ...      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count        500.000000         500.000000       500.000000   \n",
       "mean           0.131972           0.256324         0.276420   \n",
       "std            0.022739           0.159147         0.209012   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116200           0.145925         0.114475   \n",
       "50%            0.131250           0.214850         0.231400   \n",
       "75%            0.146000           0.343525         0.389450   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            500.000000      500.000000               500.000000   \n",
       "mean               0.115980        0.292212                 0.083778   \n",
       "std                0.065896        0.063366                 0.018108   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.063302        0.251700                 0.071270   \n",
       "50%                0.100650        0.283100                 0.079900   \n",
       "75%                0.166850        0.320050                 0.092065   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data seams pretty clean  without any nan value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302        1.0        17.99         10.38          122.80     1001.0   \n",
       "1    842517        1.0        20.57         17.77          132.90     1326.0   \n",
       "2  84300903        1.0        19.69         21.25          130.00     1203.0   \n",
       "3  84348301        1.0        11.42         20.38           77.58      386.1   \n",
       "4  84358402        1.0        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0  ...      2019.0            0.1622             0.6656           0.7119   \n",
       "1  ...      1956.0            0.1238             0.1866           0.2416   \n",
       "2  ...      1709.0            0.1444             0.4245           0.4504   \n",
       "3  ...       567.7            0.2098             0.8663           0.6869   \n",
       "4  ...      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  Unnamed: 32  \\\n",
       "0                0.2654          0.4601                  0.11890          NaN   \n",
       "1                0.1860          0.2750                  0.08902          NaN   \n",
       "2                0.2430          0.3613                  0.08758          NaN   \n",
       "3                0.2575          0.6638                  0.17300          NaN   \n",
       "4                0.1625          0.2364                  0.07678          NaN   \n",
       "\n",
       "   over_average  under_average  \n",
       "0            13             17  \n",
       "1             0             30  \n",
       "2             1             29  \n",
       "3            12             18  \n",
       "4             0             30  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## engineering two new features to have 32 feutures that can be encoded om 5 qubits.\n",
    "over_average = []\n",
    "under_average = []\n",
    "\n",
    "mean = {}\n",
    "std = {}\n",
    "for col in df:\n",
    "     if col not in [\"id\",\"diagnosis\" ]:\n",
    "        mean[col]=df[col].mean()\n",
    "        std[col]=df[col].std()\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    o_average=0\n",
    "    u_average=0\n",
    "    for col in df:\n",
    "        if col not in [\"id\",\"diagnosis\" ]:\n",
    "            if  row[col]> mean[col]+2* std[col]:\n",
    "                o_average = o_average + 1\n",
    "            if  row[col]< mean[col]+2* std[col]:\n",
    "                u_average= u_average + 1\n",
    "                \n",
    "    over_average.append(o_average)\n",
    "    under_average.append(u_average)\n",
    "\n",
    "df[\"over_average\"] = over_average\n",
    "df[\"under_average\"] = under_average\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "      <th>over_average</th>\n",
       "      <th>under_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>903516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.61</td>\n",
       "      <td>22.28</td>\n",
       "      <td>144.40</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>0.11670</td>\n",
       "      <td>0.20870</td>\n",
       "      <td>0.28100</td>\n",
       "      <td>0.15620</td>\n",
       "      <td>...</td>\n",
       "      <td>2081.0</td>\n",
       "      <td>0.15020</td>\n",
       "      <td>0.5717</td>\n",
       "      <td>0.70530</td>\n",
       "      <td>0.24220</td>\n",
       "      <td>0.3828</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>871641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.08</td>\n",
       "      <td>14.71</td>\n",
       "      <td>70.21</td>\n",
       "      <td>372.7</td>\n",
       "      <td>0.10060</td>\n",
       "      <td>0.05743</td>\n",
       "      <td>0.02363</td>\n",
       "      <td>0.02583</td>\n",
       "      <td>...</td>\n",
       "      <td>396.5</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.03938</td>\n",
       "      <td>0.04306</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.07313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>869104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.11</td>\n",
       "      <td>18.05</td>\n",
       "      <td>105.10</td>\n",
       "      <td>813.0</td>\n",
       "      <td>0.09721</td>\n",
       "      <td>0.11370</td>\n",
       "      <td>0.09447</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>...</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>0.13140</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.28020</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.2792</td>\n",
       "      <td>0.08158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>897880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.05</td>\n",
       "      <td>17.53</td>\n",
       "      <td>64.41</td>\n",
       "      <td>310.8</td>\n",
       "      <td>0.10070</td>\n",
       "      <td>0.07326</td>\n",
       "      <td>0.02511</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>...</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.14020</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.10550</td>\n",
       "      <td>0.06499</td>\n",
       "      <td>0.2894</td>\n",
       "      <td>0.07664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>88411702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.75</td>\n",
       "      <td>23.77</td>\n",
       "      <td>88.54</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.08043</td>\n",
       "      <td>0.06807</td>\n",
       "      <td>0.04697</td>\n",
       "      <td>0.02344</td>\n",
       "      <td>...</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.09368</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.13590</td>\n",
       "      <td>0.06106</td>\n",
       "      <td>0.2663</td>\n",
       "      <td>0.06321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "393    903516        1.0        21.61         22.28          144.40   \n",
       "173    871641        0.0        11.08         14.71           70.21   \n",
       "141    869104        1.0        16.11         18.05          105.10   \n",
       "338    897880        0.0        10.05         17.53           64.41   \n",
       "243  88411702        0.0        13.75         23.77           88.54   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "393     1407.0          0.11670           0.20870         0.28100   \n",
       "173      372.7          0.10060           0.05743         0.02363   \n",
       "141      813.0          0.09721           0.11370         0.09447   \n",
       "338      310.8          0.10070           0.07326         0.02511   \n",
       "243      590.0          0.08043           0.06807         0.04697   \n",
       "\n",
       "     concave points_mean  ...  area_worst  smoothness_worst  \\\n",
       "393              0.15620  ...      2081.0           0.15020   \n",
       "173              0.02583  ...       396.5           0.12160   \n",
       "141              0.05943  ...      1233.0           0.13140   \n",
       "338              0.01775  ...       384.0           0.14020   \n",
       "243              0.02344  ...       706.0           0.09368   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "393             0.5717          0.70530               0.24220          0.3828   \n",
       "173             0.0824          0.03938               0.04306          0.1902   \n",
       "141             0.2236          0.28020               0.12160          0.2792   \n",
       "338             0.1402          0.10550               0.06499          0.2894   \n",
       "243             0.1442          0.13590               0.06106          0.2663   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  over_average  under_average  \n",
       "393                  0.10070          NaN             8             22  \n",
       "173                  0.07313          NaN             1             29  \n",
       "141                  0.08158          NaN             0             30  \n",
       "338                  0.07664          NaN             0             30  \n",
       "243                  0.06321          NaN             0             30  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "fraud_df = df.loc[df['diagnosis'] == 0]\n",
    "non_fraud_df = df.loc[df['diagnosis'] == 1][:195]\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "sub_sample_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "sub_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sample_corr = sub_sample_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    if col not in [\"id\",\"diagnosis\" ]:\n",
    "        df[col]=df[col]/df[col].max()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_strongest_correlations(dataframe, qubits):\n",
    "        \n",
    "    class_correlations = dataframe.loc['diagnosis', :]\n",
    "    class_correlations = class_correlations.drop(index = 'diagnosis')\n",
    "    \n",
    "    feature_list = list(class_correlations.index)\n",
    "    correlation_list = [class_correlations[x] for x in feature_list]\n",
    "    \n",
    "    features = []\n",
    "    correlations = []\n",
    "    \n",
    "    for i in range(int(qubits/2)):\n",
    "        \n",
    "        \n",
    "        correlations.append(max(correlation_list))\n",
    "        features.append(feature_list[correlation_list.index(max(correlation_list))])\n",
    "        \n",
    "        del feature_list[correlation_list.index(max(correlation_list))]\n",
    "        del correlation_list[correlation_list.index(max(correlation_list))]                        \n",
    "                                      \n",
    "        correlations.append(min(correlation_list))\n",
    "        features.append(feature_list[correlation_list.index(min(correlation_list))])\n",
    "        \n",
    "        del feature_list[correlation_list.index(min(correlation_list))]\n",
    "        del correlation_list[correlation_list.index(min(correlation_list))] \n",
    "    \n",
    "    return features, correlations\n",
    "    \n",
    "    \n",
    "print(find_strongest_correlations(sub_sample_corr, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list, correlations = find_strongest_correlations(sub_sample_corr, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign=df[df[\"diagnosis\"]==0][feature_list]\n",
    "malign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign=df[df[\"diagnosis\"]!=0][feature_list]\n",
    "benign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=malign.to_numpy()\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = 2500\n",
    "nr_trash=2\n",
    "nr_latent=2\n",
    "nr_ent=0\n",
    "\n",
    "trash_qubits1=[i for i in range(nr_trash)]\n",
    "latent_qubits1=[i for i in range(nr_trash,nr_trash+nr_latent)]\n",
    "trash_qubits2=[i for i in range(nr_trash+nr_latent,2*nr_trash+nr_latent)]\n",
    "latent_qubits2=[i for i in range(2*nr_trash+nr_latent,2*(nr_trash+nr_latent))]\n",
    "aux_qubits=[i for i in range(2*(nr_trash+nr_latent),2*(nr_trash+nr_latent)+2*nr_trash)]\n",
    "swap_qubit=[2*(nr_trash+nr_latent)+2*nr_trash]\n",
    "\n",
    "qubits=[*trash_qubits1, *latent_qubits1, *trash_qubits2, *latent_qubits2, *aux_qubits, *swap_qubit]\n",
    "\n",
    "print(\"Qubits:\", qubits)\n",
    "\n",
    "#set up the device \n",
    "dev = qml.device(\"default.qubit\", wires=qubits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def training_circuit_example(init_params, encoder_params, reinit_state, x):\n",
    "    # Initialization\n",
    "    \n",
    "    \n",
    "    qml.templates.embeddings.AmplitudeEmbedding(\n",
    "        init_params,\n",
    "        wires=[*trash_qubits1, *latent_qubits1],\n",
    "        normalize=True,\n",
    "        pad_with=0.0j,\n",
    "    )\n",
    "  \n",
    "    \n",
    "    qml.templates.embeddings.AngleEmbedding(\n",
    "        init_params[:4], wires=[*trash_qubits2, *latent_qubits2], rotation='X')\n",
    "    qml.templates.embeddings.AngleEmbedding(\n",
    "        init_params[:4], wires=[*trash_qubits2, *latent_qubits2], rotation='Z')\n",
    "    \n",
    "    qml.MottonenStatePreparation(reinit_state, wires=aux_qubits)\n",
    "\n",
    "    #encoder \n",
    "    e5_patch(*encoder_params[0],*encoder_params[1], [*trash_qubits1, *latent_qubits1], [*latent_qubits2, *trash_qubits2])\n",
    "    qml.CNOT(wires=[latent_qubits1[0],trash_qubits2[0]])\n",
    "    qml.CNOT(wires=[latent_qubits2[0],trash_qubits1[0]])\n",
    "    \n",
    "    #swap test \n",
    "    trashes=[*trash_qubits1,*trash_qubits2]\n",
    "    qml.Hadamard(wires=swap_qubit[0])\n",
    "    for i in range(len(trashes)):\n",
    "        qml.CSWAP(wires=[swap_qubit[0], aux_qubits[i], trashes[i]])\n",
    "    qml.Hadamard(wires=swap_qubit[0])\n",
    "\n",
    "    return [qml.probs(i) for i in swap_qubit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.0003\n",
    "batch_size = 5\n",
    "num_samples = 0.8 # proportion of the data used for training \n",
    "\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "opt = AdamOptimizer(learning_rate, beta1=beta1, beta2=beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fid_func(output):\n",
    "    # Implemented as the Fidelity Loss\n",
    "    # output[0] because we take the probability that the state after the \n",
    "    # SWAP test is ket(0), like the reference state\n",
    "    fidelity_loss = 1 / output[0]\n",
    "    return fidelity_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(encoder_params, X):\n",
    "    reinit_state = [0 for i in range(2 ** len(aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output = training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state,x=x[0][1])[0]\n",
    "        f = fid_func(output)\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity(encoder_params, X):\n",
    "    reinit_state = [0 for _ in range(2 ** len(aux_qubits))]\n",
    "    reinit_state[0] = 1.0\n",
    "    loss = 0.0\n",
    "    for x in X:\n",
    "        output =  training_circuit_example(init_params=x[0], encoder_params=encoder_params, reinit_state=reinit_state,x=x[0][1])[0]\n",
    "       \n",
    "        f = output[0]\n",
    "        loss = loss + f\n",
    "    return loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(X, batch_size):\n",
    "    \n",
    "    random.shuffle(X)\n",
    "\n",
    "    batch_list = []\n",
    "    batch = []\n",
    "    for x in X:\n",
    "        if len(batch) < batch_size:\n",
    "            batch.append(x)\n",
    "\n",
    "        else:\n",
    "            batch_list.append(batch)\n",
    "            batch = []\n",
    "    if len(batch) != 0:\n",
    "        batch_list.append(batch)\n",
    "    return batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [ torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples))]\n",
    "test_data = [torch.tensor([input_data[i]]) for i in range(int(len(input_data)*num_samples),len(input_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=iterate_batches(training_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = training_data\n",
    "X_tes = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_encod_qubits = nr_trash + nr_latent\n",
    "nr_par_encoder =  15 * int(nr_encod_qubits*(nr_encod_qubits-1)/2)\n",
    "encoder_params = [np.random.uniform(size=(1, nr_par_encoder), requires_grad=True),np.random.uniform(size=(1, nr_par_encoder), requires_grad=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_params[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_benign = benign.to_numpy()\n",
    "benign_data = [ torch.tensor([np_benign[i]]) for i in range(len(benign.to_numpy()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist=[]\n",
    "fid_hist=[]\n",
    "\n",
    "loss_hist_test=[]\n",
    "fid_hist_test=[]\n",
    "\n",
    "benign_fid=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batches = iterate_batches(X=training_data, batch_size=batch_size)\n",
    "    for xbatch in batches:\n",
    "        encoder_params = opt.step(cost, encoder_params, X=xbatch)\n",
    "\n",
    "        \n",
    "    if epoch%5 == 0:\n",
    "        \n",
    "        loss_training = cost(encoder_params, X_training )\n",
    "        fidel = fidelity(encoder_params, X_training )\n",
    "        \n",
    "        loss_hist.append(loss_training)\n",
    "        fid_hist.append(fidel)\n",
    "        print(\"Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_training, fidel))\n",
    "\n",
    "        loss_test = cost(encoder_params, X_tes )\n",
    "        fidel = fidelity(encoder_params, X_tes )\n",
    "        loss_hist_test.append(loss_test)\n",
    "        fid_hist_test.append(fidel)\n",
    "        print(\"Test-Epoch:{} | Loss:{} | Fidelity:{}\".format(epoch, loss_test, fidel))\n",
    "        \n",
    "        b_fidel = fidelity(encoder_params, benign_data )\n",
    "        benign_fid.append(b_fidel)\n",
    "        print(\"benign fid:{}\".format(b_fidel))\n",
    "        \n",
    "        \"\"\"\n",
    "        experiment_parameters={\"autoencoder\":\"e2\",\"params\":encoder_params}\n",
    "        f=open(\"Cancer_encoder_e3-SelectedFeautures/params\"+str(epoch)+\".txt\",\"w\")\n",
    "        f.write(str(experiment_parameters))\n",
    "        f.close()\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rezults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist),label=\"train fid\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(fid_hist_test),label=\"test fid\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(benign_fid),label=\"benign fid\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Malign 2x424->compression fidelity e2\",)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"fid\")\n",
    "\n",
    "print(\"fidelity:\",fid_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist),label=\"train loss\")\n",
    "plt.plot([x for x in range(0,len(loss_hist)*5,5)],np.array(loss_hist_test),label=\"test loss\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Malign 2x424->compression loss e2\",)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "print(\"loss:\",loss_hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Cancer_encoder_e2\"\n",
    "\n",
    "Circuit_prop={   \"shots\":shots, \"nr_trash\":nr_trash, \"nr_latent\":nr_latent ,\"nr_ent\":nr_ent  }\n",
    "Training_param = { \"num_samples\" : num_samples,\n",
    "                    \"batch_size\" :batch_size,\n",
    "                    \"epochs\" :epochs,\n",
    "                    \"learning_rate\" : learning_rate ,\n",
    "                    \"beta1\" : beta1,\n",
    "                    \"beta2 \":beta2,\n",
    "                     \"optimizer\":\"Adam\"}\n",
    "\n",
    "performance={\"loss_hist\":loss_hist, \"fid_hist\":fid_hist,\n",
    "             \"loss_hist_test\":loss_hist_test, \"fid_hist_test\":fid_hist_test,\n",
    "             \"encoder_params\":encoder_params}\n",
    "\n",
    "experiment_data={\"Circuit_prop\":Circuit_prop,\n",
    "                \"Training_param\":Training_param,\n",
    "                \"performance:\":performance,\n",
    "                \"Name\":name}\n",
    "\n",
    "# open file for writing\n",
    "f = open(name+\".txt\",\"w\")\n",
    "f.write( str(experiment_data) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benign performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_benign = benign.to_numpy()\n",
    "benign_data = [ torch.tensor([np_benign[i]]) for i in range(len(benign.to_numpy()))]\n",
    "\n",
    "loss = cost(encoder_params, benign_data )\n",
    "fidel = fidelity(encoder_params, benign_data )\n",
    "\n",
    "print(\"Benign results:\")\n",
    "print(\"fidelity=\",fidel)\n",
    "print(\"loss=\",loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beningn_flist=[]\n",
    "for b in benign_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    beningn_flist.append(f.item())\n",
    "    \n",
    "print(min(beningn_flist))\n",
    "print(max(beningn_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malign_flist=[]\n",
    "for b in training_data:\n",
    "    f=fidelity(encoder_params, [b])\n",
    "    malign_flist.append(f.item())\n",
    "    \n",
    "print(min(malign_flist))\n",
    "print(max(malign_flist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beningn_flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(beningn_flist, bins = 100 ,label=\"benign\", color = \"skyblue\",alpha=0.4)\n",
    "plt.hist(malign_flist, bins =100 ,label=\"malign\",color = \"red\",alpha=0.4)\n",
    "plt.title(\"Compression fidelity\",)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
